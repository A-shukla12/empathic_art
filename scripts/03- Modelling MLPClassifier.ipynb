{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7XLJ53Yr00E4"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from google.colab import drive \n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import librosa\n","import librosa.display\n","# to play the audio files\n","from IPython.display import Audio\n","\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","import keras\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n","from keras.utils import np_utils, to_categorical\n","from keras.callbacks import ModelCheckpoint\n","\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wsl6S4SZ02xw"},"outputs":[],"source":["drive.mount('/content/drive')\n","data_path = '/content/drive/My Drive/empathic_data/data/audio-files/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oFBrCdbp1k6T"},"outputs":[],"source":["filepath = []\n","file_name = []\n","total = [] \n","for filename in os.listdir(data_path):\n","    if filename.endswith(\".wav\"): \n","      file_name.append(filename)\n","      filepath.append(data_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKIU4r624fmg"},"outputs":[],"source":["merged_path = [''.join(x) for x in zip(filepath, file_name)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iuny8KQU8FQ2"},"outputs":[],"source":["dictionary = dict(zip(file_name, merged_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2KnSRg101YC3"},"outputs":[],"source":["df = pd.read_csv('/content/merged_data.csv')\n","df['path'] = df['file_name'].map(dictionary)\n","df['Emotion'] = df['Emotion'].str.capitalize()\n","df = df[df['Emotion'] != 'Pleasure']\n","df['Emotion'].replace('Pain', 'Sad', inplace=True)\n","df['Emotion'].replace('Achievement', 'Happy', inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIQB10OGAEkD"},"outputs":[],"source":["print(\"number of files is {}\".format(len(df)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_PkOd54CrDO"},"outputs":[],"source":["df.Emotion.replace('Ps','Surprise',inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjRoVB-gBdhB"},"outputs":[],"source":["df.Emotion.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7wPmWku4BMbf"},"outputs":[],"source":["fig = plt.figure()\n","plt.figure(figsize=(8, 4))\n","sns.countplot(x=\"Emotion\", data=df)\n","plt.show();"]},{"cell_type":"code","source":["def extract_feature(file_name, mfcc, chroma, mel):\n","    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n","    if chroma:\n","        stft=np.abs(librosa.stft(X))\n","    result=np.array([])\n","    if mfcc:\n","        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n","        result=np.hstack((result, mfccs))\n","    if chroma:\n","        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n","        result=np.hstack((result, chroma))\n","    if mel:\n","        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n","        result=np.hstack((result, mel))\n","    return result"],"metadata":{"id":"rgG44pEVyYan"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Input_feature\n","def features_extractor(file,inputfeature):\n","  if inputfeature == 'mfcc':\n","    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n","    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n","    return np.mean(mfccs_features.T,axis=0)\n","\n","  if inputfeature == 'mel':\n","    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n","    mel = np.mean(librosa.feature.melspectrogram(y=audio, sr=sample_rate).T, axis=0)\n","    return mel\n","    #result = np.hstack((result, mel)) # stacking horizontally\n","    \n"],"metadata":{"id":"F50kue4dktWv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","### Now we iterate through every audio file and extract features \n","### using Mel-Frequency Cepstral Coefficients\n","\n","extracted_features=[]\n","for index_num,row in tqdm(df.iterrows()):\n","    file_name = row[\"path\"]\n","    final_class_labels=row[\"Emotion\"]\n","    #data=feature=extract_feature(file_name, mfcc=True, chroma=True, mel=True)\n","    data=features_extractor(file_name,'mfcc')\n","    extracted_features.append([data,final_class_labels])"],"metadata":{"id":"KB7k_VPWkvrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### converting extracted_features to Pandas dataframe\n","extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n","extracted_features_df.head()"],"metadata":{"id":"clbM01QiikFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Split the dataset into independent and dependent dataset\n","X=np.array(extracted_features_df['feature'].tolist())\n","y=np.array(extracted_features_df['class'].tolist())"],"metadata":{"id":"LbDtmJ5Nk3F-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Label Encoding\n","###y=np.array(pd.get_dummies(y))\n","### Label Encoder\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","labelencoder=LabelEncoder()\n","y=to_categorical(labelencoder.fit_transform(y))"],"metadata":{"id":"V0s00vjZlEnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Train Test Split\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)\n","\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"],"metadata":{"id":"ujkTxL8JlGr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","\n","mlp_gs = MLPClassifier(max_iter=100)\n","parameter_space = {\n","    'hidden_layer_sizes': [(10,30,10),(20,)],\n","    'activation': ['tanh', 'relu'],\n","    'solver': ['sgd', 'adam'],\n","    'alpha': [0.0001, 0.01],\n","    'learning_rate': ['constant','adaptive'],\n","    'batch_size' : [32,64]\n","}\n","\n","from sklearn.model_selection import GridSearchCV\n","clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=5)\n","clf.fit(X, y) # X is train samples and y is the corresponding labels"],"metadata":{"id":"8sk3UbcEMBKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Best parameters found:\\n', clf.best_params_)"],"metadata":{"id":"VarUymGPRP7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the Multi Layer Perceptron Classifier\n","model=MLPClassifier(alpha=0.01, batch_size=32, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n","#model=MLPClassifier(activation = 'relu', alpha=0.0001, batch_size=32, epsilon=1e-08, hidden_layer_sizes=(10, 30, 10), learning_rate='adaptive', max_iter=500, solver = 'adam')"],"metadata":{"id":"I2jg2Fk_lOeW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","model.fit(X_train,y_train)"],"metadata":{"id":"Ur9ceToFlQdo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict for the test set\n","y_pred=model.predict(X_test)"],"metadata":{"id":"UKUVsENdlSZe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","     \n","# Calculate the accuracy of our model\n","accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n","# Print the accuracy\n","print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n","     "],"metadata":{"id":"sSY4G-UelTz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","rmse = mean_squared_error(y_test, y_pred)\n","print(\"Loss: {:.2f}%\".format(rmse))"],"metadata":{"id":"L0ef0M3UVQaj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","print(classification_report(y_test,y_pred,target_names=['Angry','Calm','Disgust','Fear','Happy','Sad','Surprise']))\n"],"metadata":{"id":"lgidyfqRlVve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","print(f1_score(y_test, y_pred, average='macro'))"],"metadata":{"id":"DTwhfhHrSqOs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","y_pred=np.argmax(y_pred, axis=1)\n","y_test=np.argmax(y_test, axis=1)\n","matrix = confusion_matrix(y_test,y_pred)\n","\n","ax= plt.subplot()\n","sns.heatmap(matrix, linecolor='white', cmap='Blues', annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(['Angry','Calm','Disgust','Fear','Happy','Sad','Surprise'])\n","ax.yaxis.set_ticklabels(['Angry','Calm','Disgust','Fear','Happy','Sad','Surprise']);"],"metadata":{"id":"GfPkINkeTTLi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","\n","# save the model to disk\n","#filename = 'mlpClassifier_1.2.sav'\n","#joblib.dump(model, filename)"],"metadata":{"id":"HkuxUxd7l6ZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(joblib.__version__)"],"metadata":{"id":"a1qw5iVS6XSb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the model from disk\n","file_name = '/content/mlpClassifier_1.2.sav'\n","loaded_model = joblib.load(file_name)"],"metadata":{"id":"neL83_XXV6b4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model"],"metadata":{"id":"cU0xVKceOk87"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model.classes_"],"metadata":{"id":"pDr6c6EcPOFc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_new_audio(audio):\n","  #preprocess it to the input to the model\n","\n","\n","  ### Now we iterate through every audio file and extract features \n","  ### using Mel-Frequency Cepstral Coefficients\n","\n","  audio, sample_rate = librosa.load(audio, res_type='kaiser_fast') \n","  mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n","  input_val = np.mean(mfccs_features.T,axis=0)\n","  X=np.array(input_val.tolist())\n","  X = np.expand_dims(X,axis=0)\n","\n","  #pass it throught the model\n","  pred = []\n","  y_pred=loaded_model.predict(X)\n","  max_emo = np.argmax(y_pred)\n","  pred.append(max_emo)\n","  di = {0:'Angry',1: 'Calm',2: 'Disgust',3: 'Fear',4:'Happy',5:'Sad',6:'Surprise'}\n","  emo =[di.get(a) if di.get(a) else a for a in pred]\n","  #predict!\n","  print(emo)"],"metadata":{"id":"Kygyj6k_Jttm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_new_audio('/content/S01_achievement_low_02.wav')"],"metadata":{"id":"Ft7QO00BOBe-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_new_audio('/content/S02_pain_moderate_02.wav')"],"metadata":{"id":"jqjDz4RCYAmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XRz-4se5YKEL"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyOajGh6IJSK/T/2udr0lKTp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}